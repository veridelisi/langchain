{"cells":[{"cell_type":"markdown","metadata":{"id":"7Ob6GW_K0HmL"},"source":["# Create your first wordcloud\n","\n","\n","In this first chapter of the Intro to NLP course, you learn how to load a page from wikipedia and create a wordcloud.\n","\n","Let's start by installing the [wordcloud](https://github.com/amueller/word_cloud) library"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ny4s3noz0HmN"},"outputs":[],"source":["!pip install wordcloud"]},{"cell_type":"markdown","metadata":{"id":"Ky0i7K130HmN"},"source":["# Content from wikipedia\n","\n","Wikipedia is a great source of quality text.\n","We use the Wikipedia API to get the text of a page given its title\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"qPBUVBmD0HmN","executionInfo":{"status":"ok","timestamp":1694370429415,"user_tz":-180,"elapsed":1015,"user":{"displayName":"Engin Yılmaz (İspanyolca)","userId":"02667639563124232138"}}},"outputs":[],"source":["# 1) import the necessary library\n","import requests\n","\n","# 2) set the title of the page (uncomment to change the page)\n","title = 'İspanyolca'\n","\n","# 3) send a request to the wikipedia api\n","# asking to return content of the page formatted as json\n","\n","response = requests.get(\n","    'https://tr.wikipedia.org/w/api.php',\n","    params={\n","        'action': 'query',\n","        'format': 'json',\n","        'titles': title,\n","        'prop': 'extracts',\n","        'explaintext': True,\n","    }).json()\n","\n","# 4) Parse the result and extract the text\n","page = next(iter(response['query']['pages'].values()))\n","text = page['extract']\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5X0O8Jpr0HmN"},"outputs":[],"source":["# print the 1st 300 characters from the text\n","print(text[:10000])"]},{"cell_type":"markdown","metadata":{"id":"Qj8qSAry0HmO"},"source":["Let's wrap the code to get text from wikipedia into a convenient function"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"x7oDxFtf0HmO","executionInfo":{"status":"ok","timestamp":1694370438399,"user_tz":-180,"elapsed":294,"user":{"displayName":"Engin Yılmaz (İspanyolca)","userId":"02667639563124232138"}}},"outputs":[],"source":["import requests\n","\n","def wikipedia_page(title):\n","    '''\n","    This function returns the raw text of a wikipedia page\n","    given a wikipedia page title\n","    '''\n","    params = {\n","        'action': 'query',\n","        'format': 'json', # request json formatted content\n","        'titles': title, # title of the wikipedia page\n","        'prop': 'extracts',\n","        'explaintext': True\n","    }\n","    # send a request to the wikipedia api\n","    response = requests.get(\n","         'https://tr.wikipedia.org/w/api.php',\n","         params= params\n","     ).json()\n","\n","    # Parse the result\n","    page = next(iter(response['query']['pages'].values()))\n","    # return the page content\n","    if 'extract' in page.keys():\n","        return page['extract']\n","    else:\n","        return \"Page not found\"\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EQCUWTmP0HmO"},"outputs":[],"source":["# We lowercase the text to avoid having to deal with uppercase and capitalized words\n","text = wikipedia_page('İspanyolca').lower()\n","print(text)"]},{"cell_type":"markdown","metadata":{"id":"isdFKi5_0HmO"},"source":["# Create a wordcloud\n","We use the [wordcloud](https://github.com/amueller/word_cloud) library.\n","\n","Modify the parameters to get different results (size, max_words, ...)\n","\n","The Wordcloud library comes with its own list of stopwords. To disable it we set the list of stopwords to be empty.\n","\n","            stopwords = []"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_rjuaul20HmO","outputId":"5982b76b-227b-4ad3-9534-7372d6f35360","executionInfo":{"status":"ok","timestamp":1694370451742,"user_tz":-180,"elapsed":1178,"user":{"displayName":"Engin Yılmaz (İspanyolca)","userId":"02667639563124232138"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<wordcloud.wordcloud.WordCloud at 0x780e60f01300>"]},"metadata":{},"execution_count":7}],"source":["stopwords = []\n","\n","# import the wordcloud library\n","from wordcloud import WordCloud\n","# Instantiate a new wordcloud.\n","wordcloud = WordCloud(\n","        random_state = 8,\n","        normalize_plurals = False,\n","        width = 600,\n","        height= 300,\n","        max_words = 300\n","       )\n","\n","# Apply the wordcloud to the text.\n","wordcloud.generate(text)"]},{"cell_type":"markdown","metadata":{"id":"UUpGS-r10HmP"},"source":["We use matplotlib to display the word cloud as an image:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BUYGnJAD0HmP"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","# create a figure\n","fig, ax = plt.subplots(1,1, figsize = (9,6))\n","# add interpolation = bilinear to smooth things out\n","plt.imshow(wordcloud, interpolation='bilinear')\n","# and remove the axis\n","plt.axis(\"off\")"]},{"cell_type":"markdown","metadata":{"id":"T_WhvkEt0HmP"},"source":["We mostly see stopwords: _the_  _of_  _by_ _in_ etc ...\n","\n","To get rid of these stopwords, we build a new wordcloud, this time without setting the stopword parameter to an empty list."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YFCWTeJt0HmP"},"outputs":[],"source":["wordcloud = WordCloud(\n","        random_state = 8,\n","        normalize_plurals = False,\n","        width = 800,\n","        height= 400,\n","        max_words = 300)\n","wordcloud.generate(text)\n","# plot\n","fig, ax = plt.subplots(1,1, figsize = (9,6))\n","plt.imshow(wordcloud, interpolation='bilinear')\n","plt.axis(\"off\")"]},{"cell_type":"markdown","metadata":{"id":"lLGaPu-q0HmP"},"source":["A wordcloud which is much more representative of the Earth wikipedia page.\n","\n","Let's see what we get for another page, ... for instance [New York](https://en.wikipedia.org/wiki/New_York)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pet-oOSh0HmP"},"outputs":[],"source":["# Text\n","text = wikipedia_page('New_York').lower()\n","# Wordcloud\n","wordcloud = WordCloud(\n","        random_state = 8,\n","        normalize_plurals = False,\n","        width = 800,\n","        height= 400,\n","        max_words = 400)\n","wordcloud.generate(text)\n","# plot\n","fig, ax = plt.subplots(1,1, figsize = (9,6))\n","plt.imshow(wordcloud, interpolation='bilinear')\n","plt.axis(\"off\")"]},{"cell_type":"markdown","source":["# Change Background and Make a mask!"],"metadata":{"id":"xfeVfzkx1ClO"}},{"cell_type":"code","source":[],"metadata":{"id":"ljHDUSN71Bxj","executionInfo":{"status":"ok","timestamp":1694370481627,"user_tz":-180,"elapsed":321,"user":{"displayName":"Engin Yılmaz (İspanyolca)","userId":"02667639563124232138"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"oRXHAPbY1B5H","executionInfo":{"status":"ok","timestamp":1694370482594,"user_tz":-180,"elapsed":2,"user":{"displayName":"Engin Yılmaz (İspanyolca)","userId":"02667639563124232138"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"SN-zhWyY1B7-","executionInfo":{"status":"ok","timestamp":1694370483860,"user_tz":-180,"elapsed":2,"user":{"displayName":"Engin Yılmaz (İspanyolca)","userId":"02667639563124232138"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"fKAyoFOP1B-W","executionInfo":{"status":"ok","timestamp":1694370484897,"user_tz":-180,"elapsed":2,"user":{"displayName":"Engin Yılmaz (İspanyolca)","userId":"02667639563124232138"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"RBu4Z19y1CBB","executionInfo":{"status":"ok","timestamp":1694370486392,"user_tz":-180,"elapsed":2,"user":{"displayName":"Engin Yılmaz (İspanyolca)","userId":"02667639563124232138"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7vQEju-l0HmP"},"source":["\n","You get the gist :)"]},{"cell_type":"markdown","metadata":{"id":"twZkmzkC0HmP"},"source":["# Gutenberg project\n","\n","The [Gutenberg project](https://www.gutenberg.org) is another great source of text.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ddpnz_R90HmP"},"outputs":[],"source":["import requests\n","# this is the url for Frankenstein, by Mary Wollstonecraft Shelley\n","frankenstein_url = 'https://www.gutenberg.org/files/84/84-0.txt'\n","\n","# this is the url for Alice in Wonderland by Lewis Carroll\n","alice_url = 'http://www.gutenberg.org/files/11/11-0.txt'\n","\n","# get the text from Alice in Wonderland\n","r = requests.get(alice_url)\n","\n","# remove the header, the footer and some weird characters\n","text = ' '.join(r.text.split('***')[1:])\n","text = text.split(\"END OF THE PROJECT GUTENBERG\")[0]\n","text = text.encode('ascii',errors='ignore').decode('utf-8')\n","print(text)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fwpisqSC0HmP"},"outputs":[],"source":["\n","# Wordcloud\n","wordcloud = WordCloud(\n","        random_state = 8,\n","        normalize_plurals = True,\n","        width = 800,\n","        height= 400,\n","        max_words = 400)\n","wordcloud.generate(text)\n","# plot\n","fig, ax = plt.subplots(1,1, figsize = (9,6))\n","plt.imshow(wordcloud, interpolation='bilinear')\n","plt.axis(\"off\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gr8OdbDS0HmP"},"outputs":[],"source":["# and the Frankenstein Wordcloud\n","\n","import requests\n","# this is the url for Frankenstein, by Mary Wollstonecraft Shelley\n","frankenstein_url = 'https://www.gutenberg.org/files/84/84-0.txt'\n","\n","# get the text from Alice in Wonderland\n","r = requests.get(frankenstein_url)\n","\n","# remove the header, the footer and some weird characters\n","text = ' '.join(r.text.split('***')[1:])\n","text = text.split(\"END OF THE PROJECT GUTENBERG\")[0]\n","text = text.encode('ascii',errors='ignore').decode('utf-8')\n","print(text)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y9E518eZ0HmQ"},"outputs":[],"source":["# Wordcloud\n","wordcloud = WordCloud(\n","        random_state = 8,\n","        normalize_plurals = True,\n","        width = 800,\n","        height= 400,\n","        max_words = 400)\n","wordcloud.generate(text)\n","# plot\n","fig, ax = plt.subplots(1,1, figsize = (9,6))\n","plt.imshow(wordcloud, interpolation='bilinear')\n","plt.axis(\"off\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iAgY3DVm0HmQ"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}